Este proyecto aplica t茅cnicas de Machine Learning para predecir la calidad del vino bas谩ndose en caracter铆sticas f铆sico-qu铆micas.

##  Objetivo

Desarrollar y evaluar modelos de clasificaci贸n que puedan predecir la calidad del vino utilizando variables como alcohol, acidez, sulfatos, etc.

##  Dataset

- **Archivo**: `WineQT.csv`
- **Muestras**: 1,143 vinos tintos
- **Caracter铆sticas**: 11 variables f铆sico-qu铆micas
- **Variable objetivo**: Calidad del vino (escala 3-8)

### Variables analizadas:
- `fixed_acidity`: Acidez fija
- `volatile_acidity`: Acidez vol谩til
- `citric_acid`: cido c铆trico
- `residual_sugar`: Az煤car residual
- `chlorides`: Cloruros
- `free_sulfur_dioxide`: Di贸xido de azufre libre
- `total_sulfur_dioxide`: Di贸xido de azufre total
- `density`: Densidad
- `ph`: Potencial de hidr贸geno
- `sulphates`: Sulfatos
- `alcohol`: Contenido alcoh贸lico

##  Ejecuci贸n

### 1. An谩lisis Principal
```bash
jupyter notebook Wine_Quality_Classification.ipynb
```

### 2. Generar Informe PDF
```bash
python create_pdf_report.py
```

##  Estructura del Proyecto

```
 Estudios-ML/
  Wine_Quality_Classification.ipynb   # Notebook principal
  WineQT.csv                          # Dataset
  create_pdf_report.py               # Generador de informe
  README.md                          # Este archivo
  CLAUDE.md                          # Documentaci贸n t茅cnica
  model_results.csv                  # Resultados (generado)
  model_predictions.csv              # Predicciones (generado)
  Wine_Quality_Analysis_Report.pdf   # Informe final (generado)
  models/                            # Modelos entrenados (generado)
```

##  Modelos Implementados

1. **K-Nearest Neighbors (KNN)**
   - Optimizaci贸n de hiperpar谩metros: n_neighbors, weights, p
   - Preprocesamiento: StandardScaler

2. **Random Forest Classifier**
   - Optimizaci贸n: n_estimators, max_depth, min_samples_split, min_samples_leaf
   - Mejor rendimiento t铆pico

3. **Regresi贸n Log铆stica**
   - Optimizaci贸n: C (regularizaci贸n), penalty, solver
   - Preprocesamiento: StandardScaler

##  Evaluaci贸n

### M茅tricas utilizadas:
- **Accuracy**: Proporci贸n de predicciones correctas
- **Precision**: Precisi贸n por clase
- **Recall**: Sensibilidad por clase
- **F1-Score**: Media arm贸nica de precision y recall
- **Matriz de Confusi贸n**: An谩lisis detallado de errores
- **Curvas ROC**: Capacidad discriminativa

##  Informe PDF

El script `create_pdf_report.py` genera un informe profesional de 8 p谩ginas con:

1. **Portada**: Resumen del proyecto
2. **Resumen Ejecutivo**: Hallazgos principales
3. **An谩lisis Exploratorio**: Visualizaciones y estad铆sticas
4. **Comparaci贸n de Modelos**: M茅tricas y ranking
5. **Matrices de Confusi贸n**: An谩lisis de errores
6. **Importancia de Caracter铆sticas**: Factores clave
7. **Conclusiones**: Recomendaciones y pr贸ximos pasos
8. **Ap茅ndice T茅cnico**: Detalles de implementaci贸n

##  Dependencias

```bash
pip install pandas numpy scikit-learn matplotlib seaborn jupyter
```

##  Resultados Esperados

- **Mejor modelo**: Random Forest (t铆picamente ~65% accuracy)
- **Caracter铆sticas clave**: Alcohol, sulfatos, acidez vol谩til
- **Desaf铆o principal**: Clases desbalanceadas y calidades adyacentes

##  Conclusiones

- Los modelos ensemble superan a los individuales
- La calidad del vino es multifactorial
- Se requiere balanceo de clases para mejor rendimiento
- Potencial aplicaci贸n en industria vin铆cola

##  Pr贸ximos Pasos

1. Implementar t茅cnicas de balanceo (SMOTE)
2. Explorar feature engineering
3. Probar modelos avanzados (XGBoost)
4. Validar con datos de diferentes regiones

---

**Autor**: Proyecto de Machine Learning  
**Fecha**: 2024  
**Tecnolog铆as**: Python, scikit-learn, pandas, matplotlib
